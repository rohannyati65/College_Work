{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"},"colab":{"name":"Data Cleaning.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"W-7C4kn7yuC4"},"source":["# Data Cleaning\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HJ33krhAyuC9"},"source":["## 1) Dataset generation\n","\n","This section of the notebook permits to randomly generate a dataset composed of 9 columns and a parametered number of rows. Errors are also generated randomly with a possibly changeable rate for each kind of errors."]},{"cell_type":"code","metadata":{"id":"zs234nRsy6ks","executionInfo":{"status":"ok","timestamp":1611823520990,"user_tz":-120,"elapsed":620,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}}},"source":["import pandas as pd\r\n","import numpy as np\r\n","import math\r\n","\r\n","def introduce_error_name_NaN(dataframe, length, name_errors):\r\n","\tnumber_of_errors = math.floor(round(name_errors*length, 0))\r\n","\terrors_indices = np.random.choice(length, number_of_errors, replace=False)\r\n","\tdataframe.iloc[errors_indices, [dataframe.columns.get_loc('Name')]] = np.nan\r\n","\r\n","def introduce_error_missing_NaN(dataframe, length, missing_errors):\r\n","\tnumber_of_errors = math.floor(round(missing_errors*length, 0))\r\n","\terrors_indices = np.random.choice(length, number_of_errors, replace=False)\r\n","\tdataframe.iloc[errors_indices, [dataframe.columns.get_loc('Missing')]] = np.nan\r\n","\r\n","def introduce_error_category_null_values(dataframe, length, category_errors):\r\n","\tnumber_of_errors = math.floor(round(category_errors*length, 0))\r\n","\terrors_indices = np.random.choice(length, number_of_errors, replace=False)\r\n","\tfor index in errors_indices:\r\n","\t\tdataframe.iloc[index, [dataframe.columns.get_loc('Category')]] = np.random.choice(['NaN', 'null', '???', 'UNKWN'], 1, p=[0.25, 0.25, 0.25, 0.25])[0]\r\n","\r\n","def introduce_error_height_NaN(dataframe, length, height_errors):\r\n","\tnumber_of_errors = math.floor(round(height_errors*length, 0))\r\n","\terrors_indices = np.random.choice(length, number_of_errors, replace=False)\r\n","\tdataframe.iloc[errors_indices, [dataframe.columns.get_loc('Height')]] = np.nan\r\n","\r\n","def introduce_error_salary_heterogeneous(dataframe, length, salary_errors):\r\n","\tnumber_of_errors = math.floor(round(salary_errors*length, 0))\r\n","\terrors_indices = np.random.choice(length, number_of_errors, replace=False)\r\n","\tdataframe.iloc[errors_indices, [dataframe.columns.get_loc('Salary')]] = np.multiply(1000, np.random.randint(low=450, high=500, size=number_of_errors))\r\n","\r\n","def introduce_error_date(dataframe, length):\r\n","\tyears = np.random.randint(low=1950, high=2020, size=length)\r\n","\tmonths = np.random.randint(low=1, high=12, size=length)\r\n","\tdays = np.random.randint(low=1, high=28, size=length)\r\n","\tdates_array = []\r\n","\tfor i in range(length):\r\n","\t\tdate_string = '{} {}-{}'.format(months[i], years[i], days[i])\r\n","\t\tdates_array += [date_string]\r\n","\treturn dates_array\r\n","\r\n","def introduce_error_country():\r\n","\tpossible_countries = ['USA', 'uSa', 'Brasil', 'brUsil', 'France', 'Fr', 'South Africa', 'SAF', 'China', 'CHinA']\r\n","\tcountries_probabilities = [0.15, 0.05, 0.15, 0.05, 0.15, 0.05, 0.15, 0.05, 0.15, 0.05]\r\n","\treturn possible_countries, countries_probabilities\r\n","\r\n","def introduce_error_email():\r\n","\tpossible_suffixes = ['@gmail.com', '@hotmail.com', '@laposte.net', '@darkmagic', '@test.xxx', '@weneverknow.com']\r\n","\tsuffixes_probabilities = [0.41, 0.3, 0.2, 0.03, 0.03, 0.03]\r\n","\treturn possible_suffixes, suffixes_probabilities\r\n","\r\n","  \r\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"tjlNQguqxeh0","executionInfo":{"status":"ok","timestamp":1611823525259,"user_tz":-120,"elapsed":799,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}}},"source":["import random\r\n","import string\r\n","\r\n","DEFAULT_DATASET_LENGTH = 50\r\n","DEFAULT_NAME_ERRORS = 0.2\r\n","DEFAULT_MISSING_ERRORS = 0.8\r\n","DEFAULT_CATEGORY_ERRORS = 0.25\r\n","DEFAULT_HEIGHT_ERRORS = 0.15\r\n","DEFAULT_SALARY_ERRORS = 0.07\r\n","\r\n","def generate_dataset(length=DEFAULT_DATASET_LENGTH, name_errors=DEFAULT_NAME_ERRORS, missing_errors=DEFAULT_MISSING_ERRORS, category_errors=DEFAULT_CATEGORY_ERRORS,\r\n","\theight_errors=DEFAULT_HEIGHT_ERRORS, salary_errors=DEFAULT_SALARY_ERRORS):\r\n","\tdataframe = pd.DataFrame()\r\n","\tgenerate_name_column(dataframe, length)\r\n","\tintroduce_error_name_NaN(dataframe, length, name_errors)\r\n","\tgenerate_missing_column(dataframe, length)\r\n","\tintroduce_error_missing_NaN(dataframe, length, missing_errors)\r\n","\tgenerate_category_column(dataframe, length)\r\n","\tintroduce_error_category_null_values(dataframe, length, category_errors)\r\n","\tgenerate_height_column(dataframe, length)\r\n","\tintroduce_error_height_NaN(dataframe, length, height_errors)\r\n","\tgenerate_salary_column(dataframe, length)\r\n","\tintroduce_error_salary_heterogeneous(dataframe, length, salary_errors)\r\n","\tdates_array = introduce_error_date(dataframe, length)\r\n","\tgenerate_date_column(dataframe, dates_array)\r\n","\tcountries, probas = introduce_error_country()\r\n","\tgenerate_country_column(dataframe, length, countries, probas)\r\n","\tsuffixes, probas = introduce_error_email()\r\n","\tgenerate_email_column(dataframe, length, suffixes, probas)\r\n","\tgenerate_strange_column(dataframe, length)\r\n","\treturn dataframe\r\n","\r\n","def generate_name_column(dataframe, length):\r\n","\tmost_common_names = ['James', 'Mary', 'John', 'Patricia', 'Robert', 'Jennifer', 'Michael', 'Linda', 'William', 'Elizabeth',\r\n","\t\t'David', 'Barbara', 'Richard', 'Susan', 'Joseph', 'Jessica', 'Thomas', 'Sarah', 'Charles', 'Margaret']\r\n","\tdataframe[\"Name\"] = np.random.choice(most_common_names, length)\r\n","\r\n","def generate_missing_column(dataframe, length):\r\n","\tdataframe[\"Missing\"] = np.random.randint(low=0, high=100, size=length)\r\n","\r\n","def generate_category_column(dataframe, length):\r\n","\tdataframe[\"Category\"] = np.random.choice(['Classic', 'Regular', 'Special'], length)\r\n","\r\n","def generate_height_column(dataframe, length):\r\n","\tdataframe[\"Height\"] = np.round(np.random.uniform(low=1.45, high=2.10, size=length), 2)\r\n","\r\n","def generate_salary_column(dataframe, length):\r\n","\tdataframe[\"Salary\"] = np.multiply(1000, np.random.randint(low=30, high=145, size=length))\r\n","\r\n","def generate_date_column(dataframe, dates_array):\r\n","\tdataframe[\"Date\"] = dates_array\r\n","\r\n","def generate_country_column(dataframe, length, countries, probas):\r\n","\tdataframe[\"Country\"] = np.random.choice(countries, length, p=probas)\r\n","\r\n","def generate_email_column(dataframe, length, suffixes, probas):\r\n","\temail_data_array = []\r\n","\tfor row in range(length):\r\n","\t\tfirst_part = ''.join([random.choice(string.ascii_letters + string.digits) for n in range(5)])\r\n","\t\tsecond_part = ''.join([random.choice(string.ascii_letters + string.digits) for n in range(5)])\r\n","\t\textension = ''.join(np.random.choice(suffixes, 1, p=probas))\r\n","\t\trandom_data = '{}.{}{}'.format(first_part, second_part, extension)\r\n","\t\temail_data_array += [random_data]\r\n","\tdataframe[\"Email\"] = email_data_array\r\n","\r\n","def generate_strange_column(dataframe, length):\r\n","\tstrange_data_array = []\r\n","\tfor row in range(length):\r\n","\t\trandom_data = ''.join([random.choice(string.ascii_letters + string.digits) for n in range(10)])\r\n","\t\tstrange_data_array += [random_data]\r\n","\tdataframe[\"Strange\"] = strange_data_array\r\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"Ym7ShjP7yuC9","executionInfo":{"status":"ok","timestamp":1611823533364,"user_tz":-120,"elapsed":626,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"bd6960d1-1487-4b8e-f6cc-51b39ba7152a"},"source":["\n","dataframe = generate_dataset(length=500, name_errors=0.2, missing_errors=0.8, category_errors=0.25,\n","                             height_errors=0.15, salary_errors=0.07)\n","dataframe.head(10)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Missing</th>\n","      <th>Category</th>\n","      <th>Height</th>\n","      <th>Salary</th>\n","      <th>Date</th>\n","      <th>Country</th>\n","      <th>Email</th>\n","      <th>Strange</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jessica</td>\n","      <td>NaN</td>\n","      <td>Special</td>\n","      <td>1.91</td>\n","      <td>35000</td>\n","      <td>9 1979-14</td>\n","      <td>South Africa</td>\n","      <td>X5O3Q.N6tIm@laposte.net</td>\n","      <td>itbbsOZlLf</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>1.67</td>\n","      <td>88000</td>\n","      <td>8 1982-23</td>\n","      <td>China</td>\n","      <td>7j12a.pbIG1@hotmail.com</td>\n","      <td>Qdc8zoafMH</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>John</td>\n","      <td>NaN</td>\n","      <td>Regular</td>\n","      <td>NaN</td>\n","      <td>98000</td>\n","      <td>6 1990-7</td>\n","      <td>USA</td>\n","      <td>oA6Tt.cVNFO@gmail.com</td>\n","      <td>06BtnWFAqz</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Michael</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>NaN</td>\n","      <td>112000</td>\n","      <td>2 2003-22</td>\n","      <td>South Africa</td>\n","      <td>XSuTv.EXdGB@hotmail.com</td>\n","      <td>7hxB67chLd</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sarah</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>1.98</td>\n","      <td>41000</td>\n","      <td>2 2001-25</td>\n","      <td>South Africa</td>\n","      <td>plLzO.Desfh@laposte.net</td>\n","      <td>sud4edwOxv</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Barbara</td>\n","      <td>88.0</td>\n","      <td>Special</td>\n","      <td>1.91</td>\n","      <td>128000</td>\n","      <td>8 1961-4</td>\n","      <td>France</td>\n","      <td>xEYXS.oeqYU@gmail.com</td>\n","      <td>95eJlS5eks</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>null</td>\n","      <td>1.58</td>\n","      <td>81000</td>\n","      <td>3 2001-19</td>\n","      <td>China</td>\n","      <td>xPiii.2QXn8@gmail.com</td>\n","      <td>Fmmba6iNqG</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Joseph</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>1.49</td>\n","      <td>490000</td>\n","      <td>6 1950-5</td>\n","      <td>China</td>\n","      <td>AKAN5.cs86e@laposte.net</td>\n","      <td>d8Z8Kc4ZQf</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Jennifer</td>\n","      <td>38.0</td>\n","      <td>???</td>\n","      <td>1.57</td>\n","      <td>113000</td>\n","      <td>11 1980-17</td>\n","      <td>USA</td>\n","      <td>xVodN.Ft0fa@gmail.com</td>\n","      <td>5GTcMDDuBP</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Sarah</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>1.91</td>\n","      <td>71000</td>\n","      <td>7 1960-15</td>\n","      <td>France</td>\n","      <td>Aj5j6.mJyhU@gmail.com</td>\n","      <td>bHt1iLCdau</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Name  Missing  ...                    Email     Strange\n","0   Jessica      NaN  ...  X5O3Q.N6tIm@laposte.net  itbbsOZlLf\n","1       NaN      NaN  ...  7j12a.pbIG1@hotmail.com  Qdc8zoafMH\n","2      John      NaN  ...    oA6Tt.cVNFO@gmail.com  06BtnWFAqz\n","3   Michael      NaN  ...  XSuTv.EXdGB@hotmail.com  7hxB67chLd\n","4     Sarah      NaN  ...  plLzO.Desfh@laposte.net  sud4edwOxv\n","5   Barbara     88.0  ...    xEYXS.oeqYU@gmail.com  95eJlS5eks\n","6       NaN      NaN  ...    xPiii.2QXn8@gmail.com  Fmmba6iNqG\n","7    Joseph      NaN  ...  AKAN5.cs86e@laposte.net  d8Z8Kc4ZQf\n","8  Jennifer     38.0  ...    xVodN.Ft0fa@gmail.com  5GTcMDDuBP\n","9     Sarah      NaN  ...    Aj5j6.mJyhU@gmail.com  bHt1iLCdau\n","\n","[10 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"slTOA5mfyuC_"},"source":["## 2) Data Cleaning pipeline\n","\n","### a. Strange feature deletion\n","\n","Sometimes, there are features in your data that seem relatively strange, and in some cases that are really hard to understand or apprehend. They can be useless features, and to avoid wrong interpretations later in your analysis, deleting this strange feature can be an option.\n","\n","In our dataset, we created a **Strange** feature, to showcase the ability to prepare your data and continue your analysis on an appropriate perimeter of data."]},{"cell_type":"code","metadata":{"id":"mJ8VsdpeyuC_","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1611823697275,"user_tz":-120,"elapsed":941,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"6a55cb95-fe3c-44e7-dbd3-a692b108b9e6"},"source":["# Look at the first few lines of the dataset to get a sense of data\n","dataframe.head()"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Missing</th>\n","      <th>Category</th>\n","      <th>Height</th>\n","      <th>Salary</th>\n","      <th>Date</th>\n","      <th>Country</th>\n","      <th>Email</th>\n","      <th>Strange</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jessica</td>\n","      <td>NaN</td>\n","      <td>Special</td>\n","      <td>1.91</td>\n","      <td>35000</td>\n","      <td>9 1979-14</td>\n","      <td>South Africa</td>\n","      <td>X5O3Q.N6tIm@laposte.net</td>\n","      <td>itbbsOZlLf</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>1.67</td>\n","      <td>88000</td>\n","      <td>8 1982-23</td>\n","      <td>China</td>\n","      <td>7j12a.pbIG1@hotmail.com</td>\n","      <td>Qdc8zoafMH</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>John</td>\n","      <td>NaN</td>\n","      <td>Regular</td>\n","      <td>NaN</td>\n","      <td>98000</td>\n","      <td>6 1990-7</td>\n","      <td>USA</td>\n","      <td>oA6Tt.cVNFO@gmail.com</td>\n","      <td>06BtnWFAqz</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Michael</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>NaN</td>\n","      <td>112000</td>\n","      <td>2 2003-22</td>\n","      <td>South Africa</td>\n","      <td>XSuTv.EXdGB@hotmail.com</td>\n","      <td>7hxB67chLd</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sarah</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>1.98</td>\n","      <td>41000</td>\n","      <td>2 2001-25</td>\n","      <td>South Africa</td>\n","      <td>plLzO.Desfh@laposte.net</td>\n","      <td>sud4edwOxv</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Name  Missing Category  ...       Country                    Email     Strange\n","0  Jessica      NaN  Special  ...  South Africa  X5O3Q.N6tIm@laposte.net  itbbsOZlLf\n","1      NaN      NaN  Classic  ...         China  7j12a.pbIG1@hotmail.com  Qdc8zoafMH\n","2     John      NaN  Regular  ...           USA    oA6Tt.cVNFO@gmail.com  06BtnWFAqz\n","3  Michael      NaN  Classic  ...  South Africa  XSuTv.EXdGB@hotmail.com  7hxB67chLd\n","4    Sarah      NaN  Classic  ...  South Africa  plLzO.Desfh@laposte.net  sud4edwOxv\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"YWT1zpRFyuDA","executionInfo":{"status":"ok","timestamp":1611823702179,"user_tz":-120,"elapsed":864,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}}},"source":["# Drop the \"Useless\" feature of the dataset\n","dataframe = dataframe.drop(['Strange'], axis=1)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"rn3SkSvvyuDA","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1611823704237,"user_tz":-120,"elapsed":667,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"13fcc465-8e80-421b-8e45-54e575b075a6"},"source":["# Have another look on the data without the useless feature that has been deleted\n","dataframe.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Missing</th>\n","      <th>Category</th>\n","      <th>Height</th>\n","      <th>Salary</th>\n","      <th>Date</th>\n","      <th>Country</th>\n","      <th>Email</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jessica</td>\n","      <td>NaN</td>\n","      <td>Special</td>\n","      <td>1.91</td>\n","      <td>35000</td>\n","      <td>9 1979-14</td>\n","      <td>South Africa</td>\n","      <td>X5O3Q.N6tIm@laposte.net</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>1.67</td>\n","      <td>88000</td>\n","      <td>8 1982-23</td>\n","      <td>China</td>\n","      <td>7j12a.pbIG1@hotmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>John</td>\n","      <td>NaN</td>\n","      <td>Regular</td>\n","      <td>NaN</td>\n","      <td>98000</td>\n","      <td>6 1990-7</td>\n","      <td>USA</td>\n","      <td>oA6Tt.cVNFO@gmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Michael</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>NaN</td>\n","      <td>112000</td>\n","      <td>2 2003-22</td>\n","      <td>South Africa</td>\n","      <td>XSuTv.EXdGB@hotmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sarah</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>1.98</td>\n","      <td>41000</td>\n","      <td>2 2001-25</td>\n","      <td>South Africa</td>\n","      <td>plLzO.Desfh@laposte.net</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Name  Missing Category  ...       Date       Country                    Email\n","0  Jessica      NaN  Special  ...  9 1979-14  South Africa  X5O3Q.N6tIm@laposte.net\n","1      NaN      NaN  Classic  ...  8 1982-23         China  7j12a.pbIG1@hotmail.com\n","2     John      NaN  Regular  ...   6 1990-7           USA    oA6Tt.cVNFO@gmail.com\n","3  Michael      NaN  Classic  ...  2 2003-22  South Africa  XSuTv.EXdGB@hotmail.com\n","4    Sarah      NaN  Classic  ...  2 2001-25  South Africa  plLzO.Desfh@laposte.net\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"oFwbemGHyuDB"},"source":["### b. Missing values as a special category\n","\n","In this part, we will study the different values that take the **Category** feature of our generated dataset.\n","\n","We can quickly detect that there are a few values that are taken and represent a missing or an invalid value for the category. Therefore, we want to treat all these different values as a single and unique representation of the missing value concept."]},{"cell_type":"code","metadata":{"scrolled":true,"id":"97h-s9H6yuDB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611823816651,"user_tz":-120,"elapsed":656,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"0bc48ef8-cfde-41df-cc27-92593ab80999"},"source":["# Check the different values taken by data for the Category feature\n","dataframe['Category'].value_counts()"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Classic    132\n","Regular    122\n","Special    121\n","NaN         34\n","null        34\n","UNKWN       31\n","???         26\n","Name: Category, dtype: int64"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"7Mqbq2feyuDD","executionInfo":{"status":"ok","timestamp":1611823911591,"user_tz":-120,"elapsed":822,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}}},"source":["# Replace data missing values for the Category feature by a single and dedicated value\n","dataframe['Category'].replace(['NaN', 'null', 'UNKWN', '???'], ['Unknown']*4, inplace=True)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"BQwcGp9YyuDD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611823918682,"user_tz":-120,"elapsed":939,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"53c3c15e-218d-4da8-ac36-3363988fb843"},"source":["# Check the different values taken by data for the Category feature, after missing category cleaning process\n","dataframe['Category'].value_counts()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Classic    132\n","Unknown    125\n","Regular    122\n","Special    121\n","Name: Category, dtype: int64"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"IMa9JKB2yuDD"},"source":["After checking the transformed dataset with this single missing value for the Category feature, We will be able to process this feature later on knowing it can take only the values (`Classic`, `Regular`, `Special`), or the `Unknown` missing value."]},{"cell_type":"markdown","metadata":{"id":"rTJ0VOQkyuDD"},"source":["### c. Fixing spelling mistakes with known correct values\n","\n","There is a **Country** feature in our dataset that contains a few country names, but some of them are spelled or written in a strange way. That can totally happen in real life when you collect data from multiple sources and these sources do not have the same software/language references.\n"]},{"cell_type":"code","metadata":{"id":"K2R1WEXHyuDF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611823987970,"user_tz":-120,"elapsed":647,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"91cebfae-63a7-4927-dadf-61ce73dfef7c"},"source":["# Check the different values taken by data for the Country feature\n","dataframe['Country'].value_counts()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["USA             86\n","France          77\n","Brasil          76\n","South Africa    76\n","China           70\n","Fr              30\n","CHinA           25\n","uSa             21\n","SAF             21\n","brUsil          18\n","Name: Country, dtype: int64"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"TLqBk4-nyuDF"},"source":["As we can see in the different values that can take the Country feature, there are few ones that misspelled or abstracted, but we can guess the name of the real country behind it. For example, *Fr* probably means *France*, *CHinA* and *uSa* is of course a misspelling, *SAF* in an abstraction of *South Africa* and *brUsil* is totally a mistake in data."]},{"cell_type":"code","metadata":{"id":"0TOBNhWUyuDF","executionInfo":{"status":"ok","timestamp":1611824032721,"user_tz":-120,"elapsed":616,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}}},"source":["# Replace misspelled and erroneous values for the Country feature by a known correct values\n","dataframe['Country'].replace(['SAF', 'Fr', 'CHinA', 'uSa', 'brUsil'],\n","                             ['South Africa', 'France', 'China', 'USA', 'Brasil'], inplace=True)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"G9AJmjrpyuDF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611824035816,"user_tz":-120,"elapsed":658,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"c5471529-b752-4aed-9fa6-983ded7f883a"},"source":["# Check the different values taken by data for the Country feature, after fixing misspelled values\n","dataframe['Country'].value_counts()"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["USA             107\n","France          107\n","South Africa     97\n","China            95\n","Brasil           94\n","Name: Country, dtype: int64"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"r7pkHJu1yuDF"},"source":["With this spellchecking and fixing step of the Data Cleaning process, we now clearly see the different countries involved in the dataset, with no surprising or confusing values."]},{"cell_type":"markdown","metadata":{"id":"dZswYTivyuDG"},"source":["### d. Mean filling for missing values\n","\n","The **Height** feature of the dataset miss a few values, but not a large amount. In order to analyse the data without deleting too much information, it can be clever in some cases to replace missing values in numerical features by the mean of this feature.\n","\n","There are not too much outliers in this feature, so replacing missing values by the mean can be a good choice."]},{"cell_type":"code","metadata":{"id":"XJyZTN5CyuDG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611824156237,"user_tz":-120,"elapsed":613,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"da8568ae-2e5d-4292-90e5-86cceef65958"},"source":["# Check the proportion of null values in the Height feature\n","height_null_values = sum(dataframe['Height'].isnull() == True)\n","height_notnull_values = sum(dataframe['Height'].isnull() == False)\n","print(\"Height feature has {} null values and {} not null values !\".format(height_null_values, height_notnull_values))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Height feature has 75 null values and 425 not null values !\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EwyZ7GX_Z-6U","executionInfo":{"status":"ok","timestamp":1611824204035,"user_tz":-120,"elapsed":928,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"285565b6-26e4-458c-c343-c59a6c7ae6fb"},"source":["height_mean_value = round(dataframe[\"Height\"].mean(), 2)\r\n","print(height_mean_value)"],"execution_count":14,"outputs":[{"output_type":"stream","text":["1.76\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jtIT1aPNyuDG","executionInfo":{"status":"ok","timestamp":1611824233635,"user_tz":-120,"elapsed":638,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}}},"source":["# Compute the mean value of the Height feature in the dataset, and replace missing values with it\n","height_mean_value = round(dataframe[\"Height\"].mean(), 2)\n","dataframe['Height'].fillna(height_mean_value, inplace=True)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"TBp5Yon9yuDG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611824240693,"user_tz":-120,"elapsed":707,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"173c0b09-46d0-4133-e5ac-45aee88e281d"},"source":["# Check the proportion of null values in the Height feature after mean filling\n","height_null_values = sum(dataframe['Height'].isnull() == True)\n","height_notnull_values = sum(dataframe['Height'].isnull() == False)\n","print(\"Height feature has {} null values and {} not null values !\".format(height_null_values, height_notnull_values))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Height feature has 0 null values and 500 not null values !\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"0gEuVKNWagu-","executionInfo":{"status":"ok","timestamp":1611824248305,"user_tz":-120,"elapsed":633,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"0659776a-163d-435e-d1a5-b45ef79fac28"},"source":["dataframe.head()"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Missing</th>\n","      <th>Category</th>\n","      <th>Height</th>\n","      <th>Salary</th>\n","      <th>Date</th>\n","      <th>Country</th>\n","      <th>Email</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jessica</td>\n","      <td>NaN</td>\n","      <td>Special</td>\n","      <td>1.91</td>\n","      <td>35000</td>\n","      <td>9 1979-14</td>\n","      <td>South Africa</td>\n","      <td>X5O3Q.N6tIm@laposte.net</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>1.67</td>\n","      <td>88000</td>\n","      <td>8 1982-23</td>\n","      <td>China</td>\n","      <td>7j12a.pbIG1@hotmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>John</td>\n","      <td>NaN</td>\n","      <td>Regular</td>\n","      <td>1.76</td>\n","      <td>98000</td>\n","      <td>6 1990-7</td>\n","      <td>USA</td>\n","      <td>oA6Tt.cVNFO@gmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Michael</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>1.76</td>\n","      <td>112000</td>\n","      <td>2 2003-22</td>\n","      <td>South Africa</td>\n","      <td>XSuTv.EXdGB@hotmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sarah</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>1.98</td>\n","      <td>41000</td>\n","      <td>2 2001-25</td>\n","      <td>South Africa</td>\n","      <td>plLzO.Desfh@laposte.net</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Name  Missing Category  ...       Date       Country                    Email\n","0  Jessica      NaN  Special  ...  9 1979-14  South Africa  X5O3Q.N6tIm@laposte.net\n","1      NaN      NaN  Classic  ...  8 1982-23         China  7j12a.pbIG1@hotmail.com\n","2     John      NaN  Regular  ...   6 1990-7           USA    oA6Tt.cVNFO@gmail.com\n","3  Michael      NaN  Classic  ...  2 2003-22  South Africa  XSuTv.EXdGB@hotmail.com\n","4    Sarah      NaN  Classic  ...  2 2001-25  South Africa  plLzO.Desfh@laposte.net\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"6OBNKIOAyuDG"},"source":["Once the `Height` feature missing values have been replaced with the mean value, you shall heterogeneous set of values on this feature to do further analysis."]},{"cell_type":"markdown","metadata":{"id":"sYyBiIz2yuDH"},"source":["### e. Useless observations deletion\n","\n","The **Name** feature, serves as an identifier of each observation. We can face cases with real world data, where these identifiers are not filled. There are a bunch of data available, but we cannot link them to a defined indentifier, a specific object or individual.\n","\n","This generally means whathever the analysis you will make on your data, you will be blocked at some point for some cases where you need to identify a data point. Thus, it is sometimes useful to delete these points for some specific analysis."]},{"cell_type":"code","metadata":{"id":"hdvD_dHAyuDH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611824316717,"user_tz":-120,"elapsed":594,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"23ad1b65-6bc4-4249-8063-eb1946d71b40"},"source":["# Check the proportion of null values in the Name feature\n","name_null_values = sum(dataframe['Name'].isnull() == True)\n","name_notnull_values = sum(dataframe['Name'].isnull() == False)\n","print(\"Name feature has {} null values and {} not null values !\".format(name_null_values, name_notnull_values))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Name feature has 100 null values and 400 not null values !\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wjt9U5PHyuDI","executionInfo":{"status":"ok","timestamp":1611824371230,"user_tz":-120,"elapsed":622,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}}},"source":["# Delete observations where Name feature value is missing\n","dataframe = dataframe.dropna(subset=['Name'])"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"OkKkE2JHyuDI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611824374989,"user_tz":-120,"elapsed":749,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"c127da71-76f7-45cf-b5b2-287cf71c27c0"},"source":["# Check the proportion of null values in the Name feature after mean filling\n","name_null_values = sum(dataframe['Name'].isnull() == True)\n","name_notnull_values = sum(dataframe['Name'].isnull() == False)\n","print(\"Name feature has {} null values and {} not null values !\".format(name_null_values, name_notnull_values))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Name feature has 0 null values and 400 not null values !\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"P76WCikNyuDI"},"source":["Deleting observations that have missing values for the `Name` feature shall reduce your dataset size, but help you to do identification and relationships analysis easier."]},{"cell_type":"markdown","metadata":{"id":"trWCIe-IyuDJ"},"source":["### f. Useless feature deletion\n","\n","There is a **Missing** feature in my dataset that, like its name indicates, misses a large amount of data. When a feature lacks information on the majority of the data points, this means this feature does not really bring something interesting to the analysis done later on.\n","\n","In this case, this feature is considered useless and better be deleted."]},{"cell_type":"code","metadata":{"id":"jNKCEsvtyuDJ","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1611824389790,"user_tz":-120,"elapsed":633,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"70d19217-210c-4450-a081-d3455b5ad8a7"},"source":["# Check the few first lines of the dataset and especially the Missing feature values\n","dataframe.head()"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Missing</th>\n","      <th>Category</th>\n","      <th>Height</th>\n","      <th>Salary</th>\n","      <th>Date</th>\n","      <th>Country</th>\n","      <th>Email</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jessica</td>\n","      <td>NaN</td>\n","      <td>Special</td>\n","      <td>1.91</td>\n","      <td>35000</td>\n","      <td>9 1979-14</td>\n","      <td>South Africa</td>\n","      <td>X5O3Q.N6tIm@laposte.net</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>John</td>\n","      <td>NaN</td>\n","      <td>Regular</td>\n","      <td>1.76</td>\n","      <td>98000</td>\n","      <td>6 1990-7</td>\n","      <td>USA</td>\n","      <td>oA6Tt.cVNFO@gmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Michael</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>1.76</td>\n","      <td>112000</td>\n","      <td>2 2003-22</td>\n","      <td>South Africa</td>\n","      <td>XSuTv.EXdGB@hotmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sarah</td>\n","      <td>NaN</td>\n","      <td>Classic</td>\n","      <td>1.98</td>\n","      <td>41000</td>\n","      <td>2 2001-25</td>\n","      <td>South Africa</td>\n","      <td>plLzO.Desfh@laposte.net</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Barbara</td>\n","      <td>88.0</td>\n","      <td>Special</td>\n","      <td>1.91</td>\n","      <td>128000</td>\n","      <td>8 1961-4</td>\n","      <td>France</td>\n","      <td>xEYXS.oeqYU@gmail.com</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Name  Missing Category  ...       Date       Country                    Email\n","0  Jessica      NaN  Special  ...  9 1979-14  South Africa  X5O3Q.N6tIm@laposte.net\n","2     John      NaN  Regular  ...   6 1990-7           USA    oA6Tt.cVNFO@gmail.com\n","3  Michael      NaN  Classic  ...  2 2003-22  South Africa  XSuTv.EXdGB@hotmail.com\n","4    Sarah      NaN  Classic  ...  2 2001-25  South Africa  plLzO.Desfh@laposte.net\n","5  Barbara     88.0  Special  ...   8 1961-4        France    xEYXS.oeqYU@gmail.com\n","\n","[5 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"Q8nVxtJ4yuDJ","executionInfo":{"status":"ok","timestamp":1611824392408,"user_tz":-120,"elapsed":648,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}}},"source":["# Drop the \"Missing\" feature of the dataset\n","dataframe = dataframe.drop(['Missing'], axis=1)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"cSYYU8N_yuDJ","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1611824394252,"user_tz":-120,"elapsed":594,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"ddc140c6-111e-498a-902b-7ee1638d45fc"},"source":["# Look back at the dataset with Missing feature deleted\n","dataframe.head()"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Category</th>\n","      <th>Height</th>\n","      <th>Salary</th>\n","      <th>Date</th>\n","      <th>Country</th>\n","      <th>Email</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jessica</td>\n","      <td>Special</td>\n","      <td>1.91</td>\n","      <td>35000</td>\n","      <td>9 1979-14</td>\n","      <td>South Africa</td>\n","      <td>X5O3Q.N6tIm@laposte.net</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>John</td>\n","      <td>Regular</td>\n","      <td>1.76</td>\n","      <td>98000</td>\n","      <td>6 1990-7</td>\n","      <td>USA</td>\n","      <td>oA6Tt.cVNFO@gmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Michael</td>\n","      <td>Classic</td>\n","      <td>1.76</td>\n","      <td>112000</td>\n","      <td>2 2003-22</td>\n","      <td>South Africa</td>\n","      <td>XSuTv.EXdGB@hotmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sarah</td>\n","      <td>Classic</td>\n","      <td>1.98</td>\n","      <td>41000</td>\n","      <td>2 2001-25</td>\n","      <td>South Africa</td>\n","      <td>plLzO.Desfh@laposte.net</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Barbara</td>\n","      <td>Special</td>\n","      <td>1.91</td>\n","      <td>128000</td>\n","      <td>8 1961-4</td>\n","      <td>France</td>\n","      <td>xEYXS.oeqYU@gmail.com</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Name Category  Height  ...       Date       Country                    Email\n","0  Jessica  Special    1.91  ...  9 1979-14  South Africa  X5O3Q.N6tIm@laposte.net\n","2     John  Regular    1.76  ...   6 1990-7           USA    oA6Tt.cVNFO@gmail.com\n","3  Michael  Classic    1.76  ...  2 2003-22  South Africa  XSuTv.EXdGB@hotmail.com\n","4    Sarah  Classic    1.98  ...  2 2001-25  South Africa  plLzO.Desfh@laposte.net\n","5  Barbara  Special    1.91  ...   8 1961-4        France    xEYXS.oeqYU@gmail.com\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"3BjtgwKiyuDJ"},"source":["When a useless feature is deleted, models and statistics used on the dataset get more precise because they are not perturbated anymore by a lot of incorrected or missing data. It is really important to focus solely on data that has interest."]},{"cell_type":"markdown","metadata":{"id":"yStm9lqqyuDJ"},"source":["### g. Median filling for erroneous values\n","\n","The **Salary** feature of the dataset has a few values that do not seem plausible, they may be an error. When data is missing or is irrelevant in a numerical feature, and this numerical feature has potentially large outliers in it, replacing the data by the median instead of the mean can be more appropriate.\n"]},{"cell_type":"code","metadata":{"id":"j-3V6lYmyuDJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611824416773,"user_tz":-120,"elapsed":608,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"a9be6955-daf6-4421-9696-bcfd69a10af5"},"source":["max_salary = max(dataframe['Salary'])\n","min_salary = min(dataframe['Salary'])\n","mean_salary = math.ceil(round(dataframe['Salary'].mean(), 0))\n","median_salary = math.ceil(dataframe['Salary'].median())\n","print(\"Salary feature : max={}, min={}, mean={}, median={}\".format(max_salary, min_salary, mean_salary, median_salary))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Salary feature : max=499000, min=30000, mean=116760, median=95000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sStXVhFTyuDJ","executionInfo":{"status":"ok","timestamp":1611824644060,"user_tz":-120,"elapsed":1034,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}}},"source":["# Compute the mean value of the Height feature in the dataset, and replace missing values with it\n","max_salary_no_outlier = mean_salary = math.ceil(round(dataframe['Salary'].mean() * 2.5, 0))\n","dataframe = dataframe.reset_index(drop=True)\n","high_salary_indices = dataframe[(dataframe[\"Salary\"] > max_salary_no_outlier)].index\n","dataframe.iloc[high_salary_indices, [dataframe.columns.get_loc('Salary')]] = median_salary"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ml4_pJWMyuDK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611824654656,"user_tz":-120,"elapsed":610,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"566b0340-ce91-48ea-e209-95af1c864a42"},"source":["max_salary = max(dataframe[\"Salary\"])\n","min_salary = min(dataframe[\"Salary\"])\n","mean_salary = math.ceil(round(dataframe[\"Salary\"].mean(), 0))\n","median_salary = math.ceil(dataframe[\"Salary\"].median())\n","print(\"Salary feature : max={}, min={}, mean={}, median={}\".format(max_salary, min_salary, mean_salary, median_salary))"],"execution_count":26,"outputs":[{"output_type":"stream","text":["Salary feature : max=144000, min=30000, mean=88695, median=95000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Pk3kNVO-yuDK"},"source":["Once the `Salary` feature outliers have been replaced with the median value, further analysis shall be more precise and interesting."]},{"cell_type":"markdown","metadata":{"id":"K_KUZQ7UyuDK"},"source":["### h. Dates wrong formatting\n","\n","There are often dates type features in datasets, in mine we can find the evident **Date** feature. Dates features often present bad formatting according countries, times, or sources where we got your data from. It is vital to clean dates features especially on a uniform form, throughout your feature, and throughout your entire dataset.\n"]},{"cell_type":"code","metadata":{"id":"zJCDjNe-yuDK","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1611727715642,"user_tz":-120,"elapsed":735,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"e2e84827-3823-493b-bd1a-d8e88f768bbb"},"source":["# Check the first few lines of the dataset, to have a look on the dates format of my Date feature\n","dataframe.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Category</th>\n","      <th>Height</th>\n","      <th>Salary</th>\n","      <th>Date</th>\n","      <th>Country</th>\n","      <th>Email</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Margaret</td>\n","      <td>Classic</td>\n","      <td>2.07</td>\n","      <td>78000</td>\n","      <td>1 2000-25</td>\n","      <td>USA</td>\n","      <td>kCI2L.YudRY@laposte.net</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>James</td>\n","      <td>Special</td>\n","      <td>1.56</td>\n","      <td>115000</td>\n","      <td>10 1989-11</td>\n","      <td>France</td>\n","      <td>51M7M.DLkUi@gmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>William</td>\n","      <td>Classic</td>\n","      <td>1.78</td>\n","      <td>112000</td>\n","      <td>4 1952-19</td>\n","      <td>France</td>\n","      <td>ok2V8.G77eZ@gmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Susan</td>\n","      <td>Special</td>\n","      <td>2.02</td>\n","      <td>95000</td>\n","      <td>4 2002-6</td>\n","      <td>USA</td>\n","      <td>16NuU.NLewS@hotmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>David</td>\n","      <td>Classic</td>\n","      <td>1.84</td>\n","      <td>67000</td>\n","      <td>9 1976-20</td>\n","      <td>Brasil</td>\n","      <td>VhjCe.U9iQG@test.xxx</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Name Category  Height  ...        Date Country                    Email\n","0  Margaret  Classic    2.07  ...   1 2000-25     USA  kCI2L.YudRY@laposte.net\n","1     James  Special    1.56  ...  10 1989-11  France    51M7M.DLkUi@gmail.com\n","2   William  Classic    1.78  ...   4 1952-19  France    ok2V8.G77eZ@gmail.com\n","3     Susan  Special    2.02  ...    4 2002-6     USA  16NuU.NLewS@hotmail.com\n","4     David  Classic    1.84  ...   9 1976-20  Brasil     VhjCe.U9iQG@test.xxx\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"code","metadata":{"id":"gBw4WqadyuDK","executionInfo":{"status":"ok","timestamp":1611824950180,"user_tz":-120,"elapsed":607,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}}},"source":["# Transform the whole feature into a real datetime format, precising the data input format provided\n","dataframe['Date'] = pd.to_datetime(dataframe['Date'], format=\"%m %Y-%d\")\n","\n"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lBkhVPACdtRf"},"source":[""]},{"cell_type":"code","metadata":{"id":"1FKQ8UH3yuDL","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1611824952924,"user_tz":-120,"elapsed":615,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"e8a08ef1-80bd-4199-f391-6ab0a8673e23"},"source":["# Check the good transformation of dates format in the dataset\n","dataframe.head()"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Category</th>\n","      <th>Height</th>\n","      <th>Salary</th>\n","      <th>Date</th>\n","      <th>Country</th>\n","      <th>Email</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jessica</td>\n","      <td>Special</td>\n","      <td>1.91</td>\n","      <td>35000</td>\n","      <td>1979-09-14</td>\n","      <td>South Africa</td>\n","      <td>X5O3Q.N6tIm@laposte.net</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>John</td>\n","      <td>Regular</td>\n","      <td>1.76</td>\n","      <td>98000</td>\n","      <td>1990-06-07</td>\n","      <td>USA</td>\n","      <td>oA6Tt.cVNFO@gmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Michael</td>\n","      <td>Classic</td>\n","      <td>1.76</td>\n","      <td>112000</td>\n","      <td>2003-02-22</td>\n","      <td>South Africa</td>\n","      <td>XSuTv.EXdGB@hotmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sarah</td>\n","      <td>Classic</td>\n","      <td>1.98</td>\n","      <td>41000</td>\n","      <td>2001-02-25</td>\n","      <td>South Africa</td>\n","      <td>plLzO.Desfh@laposte.net</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Barbara</td>\n","      <td>Special</td>\n","      <td>1.91</td>\n","      <td>128000</td>\n","      <td>1961-08-04</td>\n","      <td>France</td>\n","      <td>xEYXS.oeqYU@gmail.com</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      Name Category  Height  ...       Date       Country                    Email\n","0  Jessica  Special    1.91  ... 1979-09-14  South Africa  X5O3Q.N6tIm@laposte.net\n","1     John  Regular    1.76  ... 1990-06-07           USA    oA6Tt.cVNFO@gmail.com\n","2  Michael  Classic    1.76  ... 2003-02-22  South Africa  XSuTv.EXdGB@hotmail.com\n","3    Sarah  Classic    1.98  ... 2001-02-25  South Africa  plLzO.Desfh@laposte.net\n","4  Barbara  Special    1.91  ... 1961-08-04        France    xEYXS.oeqYU@gmail.com\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"id":"Yfe4t8DlyuDL"},"source":["### i. Strange obervations deletion\n","\n","On some features of a dataset, strange values may sometimes appear, and it is difficult to understand whether it is a normal value or a harmful, confusing and non intentional value (that could have been introduced in the process). In the case of the **Email** feature, a very strange or non comprehensive email suffix can mean a lot of things.\n"]},{"cell_type":"code","metadata":{"id":"mDMpW6xwyuDM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611824974078,"user_tz":-120,"elapsed":609,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"393c6891-9659-4dd8-f049-da214b9f9730"},"source":["# Check all the existing email suffices in the initial dataset\n","email_suffices = pd.DataFrame({\"Suffices\": dataframe[\"Email\"].str.split(\"@\", expand=True)[1]})\n","email_suffices[\"Suffices\"].value_counts()"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["gmail.com          176\n","hotmail.com        104\n","laposte.net         81\n","darkmagic           15\n","test.xxx            12\n","weneverknow.com     12\n","Name: Suffices, dtype: int64"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"xwwr_NSQyuDM","executionInfo":{"status":"ok","timestamp":1611824984746,"user_tz":-120,"elapsed":678,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}}},"source":["# Retrieve indices of observations with harmful email suffices and delete them\n","harmful_email_indices = email_suffices[(email_suffices['Suffices'] == 'darkmagic')\n","                                       | (email_suffices['Suffices'] == 'test.xxx')\n","                                       | (email_suffices['Suffices'] == 'weneverknow.com')].index\n","dataframe.drop(harmful_email_indices, inplace=True)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"15XgrOWlyuDM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611824992745,"user_tz":-120,"elapsed":639,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"1bc7f7c7-7fd9-4675-ee9e-6cf6cf71c254"},"source":["# Check whether the deletion of observations with harmful email suffices worked \n","email_suffices = pd.DataFrame({\"Suffices\": dataframe[\"Email\"].str.split(\"@\", expand=True)[1]})\n","email_suffices[\"Suffices\"].value_counts()"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["gmail.com      176\n","hotmail.com    104\n","laposte.net     81\n","Name: Suffices, dtype: int64"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"vZltJe2XyuDM"},"source":["Now the few potentially harmful `Email` addresses have been deleted, we are narrowing our individuals with interesting data and trustable information."]},{"cell_type":"markdown","metadata":{"id":"x-8xye-lyuDN"},"source":["## 3) Conclusion\n","\n","This section of the notebook shows the results of our Data Cleaning pipeline. There are of course less columns and rows, but data is clean, readable, and ready to be further analysed with other Data Science techniques."]},{"cell_type":"code","metadata":{"id":"-0qziE2MyuDN","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"ok","timestamp":1611824995893,"user_tz":-120,"elapsed":600,"user":{"displayName":"guy uziel","photoUrl":"","userId":"02399090236232370898"}},"outputId":"d656e18b-74e6-48d0-dbe9-17a3ebc4d941"},"source":["dataframe.head(10)"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Category</th>\n","      <th>Height</th>\n","      <th>Salary</th>\n","      <th>Date</th>\n","      <th>Country</th>\n","      <th>Email</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Jessica</td>\n","      <td>Special</td>\n","      <td>1.91</td>\n","      <td>35000</td>\n","      <td>1979-09-14</td>\n","      <td>South Africa</td>\n","      <td>X5O3Q.N6tIm@laposte.net</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>John</td>\n","      <td>Regular</td>\n","      <td>1.76</td>\n","      <td>98000</td>\n","      <td>1990-06-07</td>\n","      <td>USA</td>\n","      <td>oA6Tt.cVNFO@gmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Michael</td>\n","      <td>Classic</td>\n","      <td>1.76</td>\n","      <td>112000</td>\n","      <td>2003-02-22</td>\n","      <td>South Africa</td>\n","      <td>XSuTv.EXdGB@hotmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sarah</td>\n","      <td>Classic</td>\n","      <td>1.98</td>\n","      <td>41000</td>\n","      <td>2001-02-25</td>\n","      <td>South Africa</td>\n","      <td>plLzO.Desfh@laposte.net</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Barbara</td>\n","      <td>Special</td>\n","      <td>1.91</td>\n","      <td>128000</td>\n","      <td>1961-08-04</td>\n","      <td>France</td>\n","      <td>xEYXS.oeqYU@gmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Joseph</td>\n","      <td>Classic</td>\n","      <td>1.49</td>\n","      <td>95000</td>\n","      <td>1950-06-05</td>\n","      <td>China</td>\n","      <td>AKAN5.cs86e@laposte.net</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Jennifer</td>\n","      <td>Unknown</td>\n","      <td>1.57</td>\n","      <td>113000</td>\n","      <td>1980-11-17</td>\n","      <td>USA</td>\n","      <td>xVodN.Ft0fa@gmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Sarah</td>\n","      <td>Unknown</td>\n","      <td>1.91</td>\n","      <td>71000</td>\n","      <td>1960-07-15</td>\n","      <td>France</td>\n","      <td>Aj5j6.mJyhU@gmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Patricia</td>\n","      <td>Regular</td>\n","      <td>1.99</td>\n","      <td>47000</td>\n","      <td>2014-11-11</td>\n","      <td>South Africa</td>\n","      <td>h9kCC.HQLzv@gmail.com</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Joseph</td>\n","      <td>Regular</td>\n","      <td>1.82</td>\n","      <td>38000</td>\n","      <td>1995-07-22</td>\n","      <td>Brasil</td>\n","      <td>OP25i.YKnIK@gmail.com</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Name Category  Height  ...       Date       Country                    Email\n","0    Jessica  Special    1.91  ... 1979-09-14  South Africa  X5O3Q.N6tIm@laposte.net\n","1       John  Regular    1.76  ... 1990-06-07           USA    oA6Tt.cVNFO@gmail.com\n","2    Michael  Classic    1.76  ... 2003-02-22  South Africa  XSuTv.EXdGB@hotmail.com\n","3      Sarah  Classic    1.98  ... 2001-02-25  South Africa  plLzO.Desfh@laposte.net\n","4    Barbara  Special    1.91  ... 1961-08-04        France    xEYXS.oeqYU@gmail.com\n","5     Joseph  Classic    1.49  ... 1950-06-05         China  AKAN5.cs86e@laposte.net\n","6   Jennifer  Unknown    1.57  ... 1980-11-17           USA    xVodN.Ft0fa@gmail.com\n","7      Sarah  Unknown    1.91  ... 1960-07-15        France    Aj5j6.mJyhU@gmail.com\n","8   Patricia  Regular    1.99  ... 2014-11-11  South Africa    h9kCC.HQLzv@gmail.com\n","10    Joseph  Regular    1.82  ... 1995-07-22        Brasil    OP25i.YKnIK@gmail.com\n","\n","[10 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"zZQepa_tyuDO"},"source":[""],"execution_count":null,"outputs":[]}]}